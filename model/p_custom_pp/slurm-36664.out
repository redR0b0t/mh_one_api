/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
tail: cannot open '/home/uc4ddc6536e59d9d8f8f5069efdb4e25/mh_one_api/data/custom_pred/full_pred9.csv' for reading: No such file or directory
b''
---------------got start index============0
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:34<00:34, 34.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 18.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.75s/it]
/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/intel_extension_for_pytorch/frontend.py:611: UserWarning: Conv BatchNorm folding failed during the optimize process.
  warnings.warn(
/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/intel_extension_for_pytorch/frontend.py:618: UserWarning: Linear BatchNorm folding failed during the optimize process.
  warnings.warn(
predicting 0 to 0 prompt
Traceback (most recent call last):
  File "/home/uc4ddc6536e59d9d8f8f5069efdb4e25/mh_one_api/model/p_custom_pp/p_custom.py", line 98, in <module>
    outputs = model.generate(input_ids=input_ids, do_sample=True, max_length=150)
  File "/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/peft/peft_model.py", line 1190, in generate
    outputs = self.base_model.generate(**kwargs)
  File "/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/transformers/generation/utils.py", line 1496, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/transformers/generation/utils.py", line 661, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)
  File "/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py", line 1021, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/torch/nn/modules/sparse.py", line 162, in forward
    return F.embedding(
  File "/home/uc4ddc6536e59d9d8f8f5069efdb4e25/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 2210, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, xpu:0 and cpu! (when checking argument for argument index in method wrapper_XPU__index_select)
finished precition
