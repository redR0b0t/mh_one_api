starting fine tuning model
Requirement already satisfied: datasets in /home/u131168/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.14.5)
Requirement already satisfied: torch in /home/u131168/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.0.1)
Requirement already satisfied: transformers>=4.32.0 in /opt/miniconda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (4.34.0.dev0)
Requirement already satisfied: sentencepiece in /opt/miniconda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.1.99)
Requirement already satisfied: peft in /home/u131168/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.5.0)
Requirement already satisfied: evaluate in /opt/miniconda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.4.0)
Requirement already satisfied: nltk in /opt/miniconda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (3.8.1)
Requirement already satisfied: rouge_score in /opt/miniconda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.1.2)
Requirement already satisfied: einops in /opt/miniconda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.6.1)
Requirement already satisfied: packaging in /opt/miniconda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (23.0)
Requirement already satisfied: pyyaml>=5.1 in /home/u131168/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (6.0.1)
Requirement already satisfied: multiprocess in /home/u131168/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.70.15)
Requirement already satisfied: xxhash in /home/u131168/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.3.0)
Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/u131168/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.3.7)
Requirement already satisfied: numpy>=1.17 in /home/u131168/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (1.26.0)
Requirement already satisfied: tqdm>=4.62.1 in /opt/miniconda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (4.65.0)
Requirement already satisfied: aiohttp in /home/u131168/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.8.5)
Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/miniconda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.16.4)
Requirement already satisfied: requests>=2.19.0 in /opt/miniconda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (2.28.1)
Requirement already satisfied: pandas in /home/u131168/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (2.1.0)
Requirement already satisfied: pyarrow>=8.0.0 in /home/u131168/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (13.0.0)
Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /home/u131168/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (2023.6.0)
Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (10.2.10.91)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (11.7.99)
Requirement already satisfied: triton==2.0.0 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (2.0.0)
Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (11.7.101)
Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (3.12.4)
Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (11.4.0.1)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (11.10.3.66)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (11.7.99)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (8.5.0.96)
Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (11.7.4.91)
Requirement already satisfied: sympy in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (1.12)
Requirement already satisfied: jinja2 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (3.1.2)
Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (2.14.3)
Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (10.9.0.58)
Requirement already satisfied: typing-extensions in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (4.8.0)
Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (11.7.91)
Requirement already satisfied: networkx in /home/u131168/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (3.1)
Requirement already satisfied: setuptools in /opt/miniconda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 2)) (65.6.3)
Requirement already satisfied: wheel in /opt/miniconda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 2)) (0.38.4)
Requirement already satisfied: lit in /home/u131168/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 2)) (16.0.6)
Requirement already satisfied: cmake in /home/u131168/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 2)) (3.27.5)
Requirement already satisfied: regex!=2019.12.17 in /home/u131168/.local/lib/python3.10/site-packages (from transformers>=4.32.0->-r requirements.txt (line 3)) (2023.8.8)
Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/miniconda/lib/python3.10/site-packages (from transformers>=4.32.0->-r requirements.txt (line 3)) (0.14.0)
Requirement already satisfied: safetensors>=0.3.1 in /home/u131168/.local/lib/python3.10/site-packages (from transformers>=4.32.0->-r requirements.txt (line 3)) (0.3.3)
Requirement already satisfied: accelerate in /home/u131168/.local/lib/python3.10/site-packages (from peft->-r requirements.txt (line 5)) (0.23.0)
Requirement already satisfied: psutil in /home/u131168/.local/lib/python3.10/site-packages (from peft->-r requirements.txt (line 5)) (5.9.5)
Requirement already satisfied: responses<0.19 in /opt/miniconda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 6)) (0.18.0)
Requirement already satisfied: click in /opt/miniconda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 7)) (8.1.7)
Requirement already satisfied: joblib in /opt/miniconda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 7)) (1.3.2)
Requirement already satisfied: absl-py in /opt/miniconda/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 8)) (1.4.0)
Requirement already satisfied: six>=1.14.0 in /opt/miniconda/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 8)) (1.16.0)
Requirement already satisfied: yarl<2.0,>=1.0 in /home/u131168/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.9.2)
Requirement already satisfied: aiosignal>=1.1.2 in /home/u131168/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)
Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/miniconda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (2.0.4)
Requirement already satisfied: frozenlist>=1.1.1 in /home/u131168/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.4.0)
Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/u131168/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.3)
Requirement already satisfied: attrs>=17.3.0 in /home/u131168/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (23.1.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /home/u131168/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2023.5.7)
Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (3.4)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (1.26.15)
Requirement already satisfied: MarkupSafe>=2.0 in /home/u131168/.local/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.3)
Requirement already satisfied: pytz>=2020.1 in /home/u131168/.local/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.3.post1)
Requirement already satisfied: python-dateutil>=2.8.2 in /home/u131168/.local/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.8.2)
Requirement already satisfied: tzdata>=2022.1 in /home/u131168/.local/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.3)
Requirement already satisfied: mpmath>=0.19 in /home/u131168/.local/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)
Collecting git+https://github.com/huggingface/transformers
  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-re3akdfn
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-re3akdfn
  Resolved https://github.com/huggingface/transformers to commit 408b2b3c5057b275855ae4c43c452a7f0b37aa45
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: packaging>=20.0 in /opt/miniconda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (23.0)
Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/miniconda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (0.14.0)
Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/miniconda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (0.16.4)
Requirement already satisfied: requests in /opt/miniconda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (2.28.1)
Requirement already satisfied: tqdm>=4.27 in /opt/miniconda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (4.65.0)
Requirement already satisfied: regex!=2019.12.17 in /home/u131168/.local/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (2023.8.8)
Requirement already satisfied: safetensors>=0.3.1 in /home/u131168/.local/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (0.3.3)
Requirement already satisfied: pyyaml>=5.1 in /home/u131168/.local/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (6.0.1)
Requirement already satisfied: numpy>=1.17 in /home/u131168/.local/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (1.26.0)
Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (3.12.4)
Requirement already satisfied: fsspec in /home/u131168/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0.dev0) (2023.6.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/u131168/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0.dev0) (4.8.0)
Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (2023.5.7)
Requirement already satisfied: charset-normalizer<3,>=2 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (2.0.4)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (1.26.15)
Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (3.4)
ls: cannot access '/home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/': No such file or directory
/home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/
/opt/miniconda/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.
  warn("The installed version of bitsandbytes was compiled without GPU support. "
/opt/miniconda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32
-------------------starting-script
-------------------setting up-logging
09/26/2023 23:43:24 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False
09/26/2023 23:43:24 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=0,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0001,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/runs/Sep26_23-43-24_idc-beta-batch-pvc-node-05,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=2,
per_device_train_batch_size=2,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1,
save_on_each_node=False,
save_safetensors=False,
save_steps=100,
save_strategy=steps,
save_total_limit=2,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)
/home/u131168/.local/lib/python3.10/site-packages/datasets/load.py:2089: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=None' instead.
  warnings.warn(
Using custom data configuration default-767521a3d70a4457
----------------------detecting checkpoint
09/26/2023 23:43:24 - INFO - datasets.builder - Using custom data configuration default-767521a3d70a4457
Loading Dataset Infos from /home/u131168/.local/lib/python3.10/site-packages/datasets/packaged_modules/csv
09/26/2023 23:43:24 - INFO - datasets.info - Loading Dataset Infos from /home/u131168/.local/lib/python3.10/site-packages/datasets/packaged_modules/csv
Generating dataset csv (/home/u131168/.cache/huggingface/datasets/csv/default-767521a3d70a4457/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)
09/26/2023 23:43:24 - INFO - datasets.builder - Generating dataset csv (/home/u131168/.cache/huggingface/datasets/csv/default-767521a3d70a4457/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)
Downloading and preparing dataset csv/default to /home/u131168/.cache/huggingface/datasets/csv/default-767521a3d70a4457/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...
09/26/2023 23:43:24 - INFO - datasets.builder - Downloading and preparing dataset csv/default to /home/u131168/.cache/huggingface/datasets/csv/default-767521a3d70a4457/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 6000.43it/s]
Downloading took 0.0 min
09/26/2023 23:43:24 - INFO - datasets.download.download_manager - Downloading took 0.0 min
Checksum Computation took 0.0 min
09/26/2023 23:43:24 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 63.54it/s]
Generating train split
09/26/2023 23:43:24 - INFO - datasets.builder - Generating train split
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 10000 examples [00:00, 26584.25 examples/s]Generating train split: 20000 examples [00:00, 27186.31 examples/s]Generating train split: 30000 examples [00:01, 27729.58 examples/s]Generating train split: 40000 examples [00:01, 28735.79 examples/s]Generating train split: 50000 examples [00:01, 28978.53 examples/s]Generating train split: 60000 examples [00:02, 29043.63 examples/s]Generating train split: 66611 examples [00:02, 29382.94 examples/s]Generating train split: 66611 examples [00:02, 24970.54 examples/s]
Unable to verify splits sizes.
09/26/2023 23:43:27 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.
Dataset csv downloaded and prepared to /home/u131168/.cache/huggingface/datasets/csv/default-767521a3d70a4457/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.
09/26/2023 23:43:27 - INFO - datasets.builder - Dataset csv downloaded and prepared to /home/u131168/.cache/huggingface/datasets/csv/default-767521a3d70a4457/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.
[INFO|tokenization_utils_base.py:2037] 2023-09-26 23:43:27,860 >> loading file spiece.model from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/spiece.model
[INFO|tokenization_utils_base.py:2037] 2023-09-26 23:43:27,860 >> loading file tokenizer.json from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/tokenizer.json
[INFO|tokenization_utils_base.py:2037] 2023-09-26 23:43:27,860 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2037] 2023-09-26 23:43:27,860 >> loading file special_tokens_map.json from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/special_tokens_map.json
[INFO|tokenization_utils_base.py:2037] 2023-09-26 23:43:27,860 >> loading file tokenizer_config.json from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/tokenizer_config.json
[WARNING|logging.py:305] 2023-09-26 23:43:27,860 >> Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.
Running tokenizer on train dataset:   0%|          | 0/66611 [00:00<?, ? examples/s]Caching processed dataset at /home/u131168/.cache/huggingface/datasets/csv/default-767521a3d70a4457/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-e5c11e4bdad6a309.arrow
-------------------preparing features
09/26/2023 23:43:30 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/u131168/.cache/huggingface/datasets/csv/default-767521a3d70a4457/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-e5c11e4bdad6a309.arrow
Running tokenizer on train dataset:   2%|▏         | 1000/66611 [00:02<02:49, 387.84 examples/s]Running tokenizer on train dataset:   3%|▎         | 2000/66611 [00:05<02:46, 388.97 examples/s]Running tokenizer on train dataset:   5%|▍         | 3000/66611 [00:07<02:44, 386.20 examples/s]Running tokenizer on train dataset:   6%|▌         | 4000/66611 [00:10<02:47, 373.21 examples/s]Running tokenizer on train dataset:   8%|▊         | 5000/66611 [00:13<02:48, 364.92 examples/s]Running tokenizer on train dataset:   9%|▉         | 6000/66611 [00:16<02:46, 363.23 examples/s]Running tokenizer on train dataset:  11%|█         | 7000/66611 [00:19<02:45, 360.20 examples/s]Running tokenizer on train dataset:  12%|█▏        | 8000/66611 [00:21<02:43, 358.95 examples/s]Running tokenizer on train dataset:  14%|█▎        | 9000/66611 [00:24<02:41, 357.03 examples/s]Running tokenizer on train dataset:  15%|█▌        | 10000/66611 [00:27<02:40, 353.39 examples/s]Running tokenizer on train dataset:  17%|█▋        | 11000/66611 [00:30<02:38, 351.58 examples/s]Running tokenizer on train dataset:  18%|█▊        | 12000/66611 [00:33<02:37, 346.28 examples/s]Running tokenizer on train dataset:  20%|█▉        | 13000/66611 [00:36<02:37, 340.53 examples/s]Running tokenizer on train dataset:  21%|██        | 14000/66611 [00:39<02:34, 340.40 examples/s]Running tokenizer on train dataset:  23%|██▎       | 15000/66611 [00:42<02:32, 338.67 examples/s]Running tokenizer on train dataset:  24%|██▍       | 16000/66611 [00:45<02:31, 334.28 examples/s]Running tokenizer on train dataset:  26%|██▌       | 17000/66611 [00:48<02:29, 331.95 examples/s]Running tokenizer on train dataset:  27%|██▋       | 18000/66611 [00:51<02:27, 330.14 examples/s]Running tokenizer on train dataset:  29%|██▊       | 19000/66611 [00:54<02:24, 328.96 examples/s]Running tokenizer on train dataset:  30%|███       | 20000/66611 [00:56<02:04, 374.95 examples/s]Running tokenizer on train dataset:  32%|███▏      | 21000/66611 [00:59<02:07, 358.52 examples/s]Running tokenizer on train dataset:  33%|███▎      | 22000/66611 [01:02<02:08, 347.28 examples/s]Running tokenizer on train dataset:  35%|███▍      | 23000/66611 [01:05<02:08, 339.01 examples/s]Running tokenizer on train dataset:  36%|███▌      | 24000/66611 [01:08<02:05, 339.00 examples/s]Running tokenizer on train dataset:  38%|███▊      | 25000/66611 [01:11<02:02, 339.63 examples/s]Running tokenizer on train dataset:  39%|███▉      | 26000/66611 [01:12<01:32, 436.86 examples/s]Running tokenizer on train dataset:  41%|████      | 27000/66611 [01:13<01:12, 547.58 examples/s]Running tokenizer on train dataset:  42%|████▏     | 28000/66611 [01:13<00:58, 665.18 examples/s]Running tokenizer on train dataset:  44%|████▎     | 29000/66611 [01:14<00:48, 782.19 examples/s]Running tokenizer on train dataset:  45%|████▌     | 30000/66611 [01:15<00:41, 892.78 examples/s]Running tokenizer on train dataset:  47%|████▋     | 31000/66611 [01:16<00:35, 992.65 examples/s]Running tokenizer on train dataset:  48%|████▊     | 32000/66611 [01:16<00:32, 1076.87 examples/s]Running tokenizer on train dataset:  50%|████▉     | 33000/66611 [01:17<00:29, 1139.09 examples/s]Running tokenizer on train dataset:  51%|█████     | 34000/66611 [01:18<00:27, 1189.30 examples/s]Running tokenizer on train dataset:  53%|█████▎    | 35000/66611 [01:19<00:25, 1228.45 examples/s]Running tokenizer on train dataset:  54%|█████▍    | 36000/66611 [01:19<00:24, 1258.75 examples/s]Running tokenizer on train dataset:  56%|█████▌    | 37000/66611 [01:20<00:23, 1263.49 examples/s]Running tokenizer on train dataset:  57%|█████▋    | 38000/66611 [01:21<00:22, 1282.02 examples/s]Running tokenizer on train dataset:  59%|█████▊    | 39000/66611 [01:22<00:21, 1292.07 examples/s]Running tokenizer on train dataset:  60%|██████    | 40000/66611 [01:22<00:20, 1299.33 examples/s]Running tokenizer on train dataset:  62%|██████▏   | 41000/66611 [01:23<00:19, 1307.94 examples/s]Running tokenizer on train dataset:  63%|██████▎   | 42000/66611 [01:24<00:18, 1316.51 examples/s]Running tokenizer on train dataset:  65%|██████▍   | 43000/66611 [01:25<00:17, 1321.38 examples/s]Running tokenizer on train dataset:  66%|██████▌   | 44000/66611 [01:25<00:17, 1323.50 examples/s]Running tokenizer on train dataset:  68%|██████▊   | 45000/66611 [01:26<00:16, 1321.66 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 46000/66611 [01:27<00:15, 1325.98 examples/s]Running tokenizer on train dataset:  71%|███████   | 47000/66611 [01:28<00:14, 1323.72 examples/s]Running tokenizer on train dataset:  72%|███████▏  | 48000/66611 [01:28<00:14, 1326.58 examples/s]Running tokenizer on train dataset:  74%|███████▎  | 49000/66611 [01:29<00:13, 1327.56 examples/s]Running tokenizer on train dataset:  75%|███████▌  | 50000/66611 [01:30<00:12, 1331.96 examples/s]Running tokenizer on train dataset:  77%|███████▋  | 51000/66611 [01:31<00:11, 1332.10 examples/s]Running tokenizer on train dataset:  78%|███████▊  | 52000/66611 [01:31<00:10, 1336.58 examples/s]Running tokenizer on train dataset:  80%|███████▉  | 53000/66611 [01:32<00:10, 1332.31 examples/s]Running tokenizer on train dataset:  81%|████████  | 54000/66611 [01:33<00:09, 1333.35 examples/s]Running tokenizer on train dataset:  83%|████████▎ | 55000/66611 [01:34<00:08, 1334.73 examples/s]Running tokenizer on train dataset:  84%|████████▍ | 56000/66611 [01:34<00:07, 1330.66 examples/s]Running tokenizer on train dataset:  86%|████████▌ | 57000/66611 [01:35<00:07, 1307.17 examples/s]Running tokenizer on train dataset:  87%|████████▋ | 58000/66611 [01:36<00:06, 1317.06 examples/s]Running tokenizer on train dataset:  89%|████████▊ | 59000/66611 [01:37<00:05, 1321.43 examples/s]Running tokenizer on train dataset:  90%|█████████ | 60000/66611 [01:38<00:05, 1321.92 examples/s]Running tokenizer on train dataset:  92%|█████████▏| 61000/66611 [01:38<00:04, 1326.51 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 62000/66611 [01:39<00:03, 1321.03 examples/s]Running tokenizer on train dataset:  95%|█████████▍| 63000/66611 [01:40<00:02, 1324.51 examples/s]Running tokenizer on train dataset:  96%|█████████▌| 64000/66611 [01:41<00:01, 1329.56 examples/s]Running tokenizer on train dataset:  98%|█████████▊| 65000/66611 [01:41<00:01, 1329.95 examples/s]Running tokenizer on train dataset:  99%|█████████▉| 66000/66611 [01:42<00:00, 1329.65 examples/s]Running tokenizer on train dataset: 100%|██████████| 66611/66611 [01:42<00:00, 1332.60 examples/s]Running tokenizer on train dataset: 100%|██████████| 66611/66611 [01:43<00:00, 645.38 examples/s] 
[INFO|configuration_utils.py:715] 2023-09-26 23:45:11,809 >> loading configuration file config.json from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/config.json
[INFO|configuration_utils.py:775] 2023-09-26 23:45:11,811 >> Model config T5Config {
  "_name_or_path": "google/flan-t5-xl",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "classifier_dropout": 0.0,
  "d_ff": 5120,
  "d_kv": 64,
  "d_model": 2048,
  "decoder_start_token_id": 0,
  "dense_act_fn": "gelu_new",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "gated-gelu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": true,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 32,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.34.0.dev0",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|modeling_utils.py:2892] 2023-09-26 23:45:11,826 >> loading weights file pytorch_model.bin from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/pytorch_model.bin.index.json
[INFO|configuration_utils.py:770] 2023-09-26 23:45:11,833 >> Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0
}

-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
-------------------preparing features
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.89s/it]
[INFO|modeling_utils.py:3671] 2023-09-26 23:45:29,749 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.

[INFO|modeling_utils.py:3679] 2023-09-26 23:45:29,749 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at google/flan-t5-xl.
If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:730] 2023-09-26 23:45:29,836 >> loading configuration file generation_config.json from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/generation_config.json
[INFO|configuration_utils.py:770] 2023-09-26 23:45:29,836 >> Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0
}

[WARNING|modeling_utils.py:1535] 2023-09-26 23:45:29,844 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32100. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[INFO|trainer.py:1758] 2023-09-26 23:45:34,277 >> ***** Running training *****
[INFO|trainer.py:1759] 2023-09-26 23:45:34,277 >>   Num examples = 66,611
[INFO|trainer.py:1760] 2023-09-26 23:45:34,277 >>   Num Epochs = 3
[INFO|trainer.py:1761] 2023-09-26 23:45:34,277 >>   Instantaneous batch size per device = 2
[INFO|trainer.py:1764] 2023-09-26 23:45:34,277 >>   Total train batch size (w. parallel, distributed & accumulation) = 2
[INFO|trainer.py:1765] 2023-09-26 23:45:34,277 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1766] 2023-09-26 23:45:34,277 >>   Total optimization steps = 99,918
[INFO|trainer.py:1767] 2023-09-26 23:45:34,279 >>   Number of trainable parameters = 4,718,592
trainable params: 4,718,592 || all params: 2,854,361,088 || trainable%: 0.1653116706164963
-------------------traing-model
  0%|          | 0/99918 [00:00<?, ?it/s][WARNING|logging.py:290] 2023-09-26 23:45:34,287 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/99918 [00:04<133:27:37,  4.81s/it]  0%|          | 2/99918 [00:08<107:48:46,  3.88s/it]  0%|          | 3/99918 [00:11<101:13:02,  3.65s/it]  0%|          | 4/99918 [00:19<150:53:09,  5.44s/it]  0%|          | 5/99918 [00:23<138:36:04,  4.99s/it]  0%|          | 6/99918 [00:26<118:14:20,  4.26s/it]  0%|          | 7/99918 [00:30<112:18:32,  4.05s/it]  0%|          | 8/99918 [00:33<101:10:38,  3.65s/it]  0%|          | 9/99918 [00:35<94:02:21,  3.39s/it]   0%|          | 10/99918 [00:42<118:22:11,  4.27s/it]                                                        0%|          | 10/99918 [00:42<118:22:11,  4.27s/it]  0%|          | 11/99918 [00:46<123:38:08,  4.46s/it]  0%|          | 12/99918 [00:51<128:15:11,  4.62s/it]  0%|          | 13/99918 [00:55<119:13:05,  4.30s/it]  0%|          | 14/99918 [00:58<110:21:42,  3.98s/it]  0%|          | 15/99918 [01:01<97:14:15,  3.50s/it]   0%|          | 16/99918 [01:03<85:13:58,  3.07s/it]  0%|          | 17/99918 [01:04<72:18:51,  2.61s/it]  0%|          | 18/99918 [01:07<77:06:48,  2.78s/it]  0%|          | 19/99918 [01:13<98:50:31,  3.56s/it]  0%|          | 20/99918 [01:19<116:44:45,  4.21s/it]                                                        0%|          | 20/99918 [01:19<116:44:45,  4.21s/it]  0%|          | 21/99918 [01:22<113:52:45,  4.10s/it]  0%|          | 22/99918 [01:27<119:41:45,  4.31s/it]  0%|          | 23/99918 [01:31<115:49:41,  4.17s/it]  0%|          | 24/99918 [01:34<103:46:10,  3.74s/it]  0%|          | 25/99918 [01:37<96:45:59,  3.49s/it]   0%|          | 26/99918 [01:39<88:47:10,  3.20s/it]  0%|          | 27/99918 [01:42<84:38:25,  3.05s/it]  0%|          | 28/99918 [01:45<82:34:12,  2.98s/it]  0%|          | 29/99918 [01:47<80:16:25,  2.89s/it]  0%|          | 30/99918 [01:50<74:20:50,  2.68s/it]                                                       0%|          | 30/99918 [01:50<74:20:50,  2.68s/it]  0%|          | 31/99918 [01:51<64:17:55,  2.32s/it]  0%|          | 32/99918 [01:54<68:31:18,  2.47s/it]  0%|          | 33/99918 [01:58<79:47:28,  2.88s/it]  0%|          | 34/99918 [02:01<82:04:54,  2.96s/it]  0%|          | 35/99918 [02:05<89:13:36,  3.22s/it]  0%|          | 36/99918 [02:09<96:20:16,  3.47s/it]  0%|          | 37/99918 [02:12<94:18:28,  3.40s/it]  0%|          | 38/99918 [02:15<90:48:54,  3.27s/it]  0%|          | 39/99918 [02:18<89:32:06,  3.23s/it]  0%|          | 40/99918 [02:21<90:43:45,  3.27s/it]                                                       0%|          | 40/99918 [02:21<90:43:45,  3.27s/it]  0%|          | 41/99918 [02:26<99:26:00,  3.58s/it]  0%|          | 42/99918 [02:29<95:20:21,  3.44s/it]  0%|          | 43/99918 [02:31<87:06:49,  3.14s/it]  0%|          | 44/99918 [02:34<83:06:31,  3.00s/it]  0%|          | 45/99918 [02:38<91:29:07,  3.30s/it]  0%|          | 46/99918 [02:41<89:46:13,  3.24s/it]  0%|          | 47/99918 [02:44<84:48:02,  3.06s/it]  0%|          | 48/99918 [02:46<78:54:06,  2.84s/it]  0%|          | 49/99918 [02:49<77:02:26,  2.78s/it]  0%|          | 50/99918 [02:51<74:46:24,  2.70s/it]                                                       0%|          | 50/99918 [02:51<74:46:24,  2.70s/it]  0%|          | 51/99918 [02:54<76:08:48,  2.74s/it]  0%|          | 52/99918 [02:56<73:50:30,  2.66s/it]  0%|          | 53/99918 [02:59<70:10:36,  2.53s/it]  0%|          | 54/99918 [03:01<69:06:06,  2.49s/it]  0%|          | 55/99918 [03:04<70:21:47,  2.54s/it]  0%|          | 56/99918 [03:08<81:27:08,  2.94s/it]  0%|          | 57/99918 [03:11<87:35:15,  3.16s/it]  0%|          | 58/99918 [03:14<82:53:50,  2.99s/it]  0%|          | 59/99918 [03:17<80:17:36,  2.89s/it]  0%|          | 60/99918 [03:19<80:11:03,  2.89s/it]                                                       0%|          | 60/99918 [03:19<80:11:03,  2.89s/it]  0%|          | 61/99918 [03:22<80:20:21,  2.90s/it]  0%|          | 62/99918 [03:25<78:46:18,  2.84s/it]  0%|          | 63/99918 [03:28<77:25:14,  2.79s/it]  0%|          | 64/99918 [03:30<74:42:06,  2.69s/it]  0%|          | 65/99918 [03:33<73:34:44,  2.65s/it]  0%|          | 66/99918 [03:35<73:58:42,  2.67s/it]  0%|          | 67/99918 [03:38<73:49:25,  2.66s/it]  0%|          | 68/99918 [03:40<64:15:36,  2.32s/it]  0%|          | 69/99918 [03:42<65:45:48,  2.37s/it]  0%|          | 70/99918 [03:45<70:05:07,  2.53s/it]                                                       0%|          | 70/99918 [03:45<70:05:07,  2.53s/it]  0%|          | 71/99918 [03:48<77:21:39,  2.79s/it]  0%|          | 72/99918 [03:51<79:04:22,  2.85s/it]  0%|          | 73/99918 [03:54<75:38:31,  2.73s/it]  0%|          | 74/99918 [03:57<83:02:46,  2.99s/it]  0%|          | 75/99918 [03:59<74:32:45,  2.69s/it]  0%|          | 76/99918 [04:03<78:25:08,  2.83s/it]  0%|          | 77/99918 [04:06<83:42:13,  3.02s/it]  0%|          | 78/99918 [04:09<85:43:58,  3.09s/it]  0%|          | 79/99918 [04:12<83:38:04,  3.02s/it]  0%|          | 80/99918 [04:14<72:40:31,  2.62s/it]                                                       0%|          | 80/99918 [04:14<72:40:31,  2.62s/it]  0%|          | 81/99918 [04:17<76:35:26,  2.76s/it]  0%|          | 82/99918 [04:21<88:50:16,  3.20s/it]  0%|          | 83/99918 [04:24<82:53:45,  2.99s/it]  0%|          | 84/99918 [04:28<91:23:59,  3.30s/it]  0%|          | 85/99918 [04:31<87:28:56,  3.15s/it]  0%|          | 86/99918 [04:33<84:19:24,  3.04s/it]  0%|          | 87/99918 [04:37<89:14:34,  3.22s/it]  0%|          | 88/99918 [04:39<82:31:27,  2.98s/it]  0%|          | 89/99918 [04:43<88:30:08,  3.19s/it]  0%|          | 90/99918 [04:45<81:32:12,  2.94s/it]                                                       0%|          | 90/99918 [04:45<81:32:12,  2.94s/it]  0%|          | 91/99918 [04:47<67:39:02,  2.44s/it]  0%|          | 92/99918 [04:50<73:58:22,  2.67s/it]  0%|          | 93/99918 [04:53<78:54:11,  2.85s/it]  0%|          | 94/99918 [04:56<79:20:20,  2.86s/it]  0%|          | 95/99918 [04:59<79:38:41,  2.87s/it]  0%|          | 96/99918 [05:01<77:06:34,  2.78s/it]  0%|          | 97/99918 [05:05<81:45:30,  2.95s/it]  0%|          | 98/99918 [05:09<89:10:01,  3.22s/it]  0%|          | 99/99918 [05:13<94:53:35,  3.42s/it]  0%|          | 100/99918 [05:16<99:00:32,  3.57s/it]                                                        0%|          | 100/99918 [05:16<99:00:32,  3.57s/it][INFO|trainer.py:2937] 2023-09-26 23:50:51,264 >> Saving model checkpoint to /home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-100
  0%|          | 101/99918 [05:18<82:48:38,  2.99s/it]  0%|          | 102/99918 [05:21<79:00:17,  2.85s/it]  0%|          | 103/99918 [05:24<83:11:28,  3.00s/it]  0%|          | 104/99918 [05:27<81:46:19,  2.95s/it]  0%|          | 105/99918 [05:29<78:55:33,  2.85s/it]  0%|          | 106/99918 [05:32<77:28:13,  2.79s/it]  0%|          | 107/99918 [05:36<87:22:27,  3.15s/it]  0%|          | 108/99918 [05:39<82:10:28,  2.96s/it]  0%|          | 109/99918 [05:40<69:14:55,  2.50s/it]  0%|          | 110/99918 [05:43<71:36:10,  2.58s/it]                                                        0%|          | 110/99918 [05:43<71:36:10,  2.58s/it]  0%|          | 111/99918 [05:47<83:04:26,  3.00s/it]  0%|          | 112/99918 [05:49<79:16:42,  2.86s/it]  0%|          | 113/99918 [05:52<76:07:27,  2.75s/it]  0%|          | 114/99918 [05:54<74:14:30,  2.68s/it]  0%|          | 115/99918 [05:58<80:17:33,  2.90s/it]  0%|          | 116/99918 [05:59<67:39:31,  2.44s/it]  0%|          | 117/99918 [06:03<77:06:03,  2.78s/it]  0%|          | 118/99918 [06:04<66:08:35,  2.39s/it]  0%|          | 119/99918 [06:06<65:21:00,  2.36s/it]  0%|          | 120/99918 [06:09<65:21:13,  2.36s/it]                                                        0%|          | 120/99918 [06:09<65:21:13,  2.36s/it]  0%|          | 121/99918 [06:10<55:58:55,  2.02s/it]  0%|          | 122/99918 [06:12<58:44:56,  2.12s/it]  0%|          | 123/99918 [06:16<69:23:13,  2.50s/it]  0%|          | 124/99918 [06:18<71:23:21,  2.58s/it]  0%|          | 125/99918 [06:21<71:41:16,  2.59s/it]  0%|          | 126/99918 [06:23<69:20:01,  2.50s/it]  0%|          | 127/99918 [06:26<70:03:06,  2.53s/it]  0%|          | 128/99918 [06:27<60:35:56,  2.19s/it]  0%|          | 129/99918 [06:30<61:26:17,  2.22s/it]  0%|          | 130/99918 [06:32<62:28:24,  2.25s/it]                                                        0%|          | 130/99918 [06:32<62:28:24,  2.25s/it]  0%|          | 131/99918 [06:35<66:29:55,  2.40s/it]  0%|          | 132/99918 [06:37<66:39:53,  2.41s/it]  0%|          | 133/99918 [06:39<58:51:08,  2.12s/it]  0%|          | 134/99918 [06:41<60:13:11,  2.17s/it]  0%|          | 135/99918 [06:44<71:04:55,  2.56s/it]  0%|          | 136/99918 [06:46<61:48:32,  2.23s/it]  0%|          | 137/99918 [06:50<73:50:00,  2.66s/it]  0%|          | 138/99918 [06:53<76:28:28,  2.76s/it]  0%|          | 139/99918 [06:55<73:42:40,  2.66s/it]  0%|          | 140/99918 [06:58<75:06:48,  2.71s/it]                                                        0%|          | 140/99918 [06:58<75:06:48,  2.71s/it]  0%|          | 141/99918 [07:00<73:25:24,  2.65s/it]  0%|          | 142/99918 [07:03<72:07:49,  2.60s/it]  0%|          | 143/99918 [07:05<72:12:37,  2.61s/it]  0%|          | 144/99918 [07:08<70:40:23,  2.55s/it]  0%|          | 145/99918 [07:11<72:07:07,  2.60s/it]  0%|          | 146/99918 [07:13<69:28:32,  2.51s/it]  0%|          | 147/99918 [07:15<68:50:56,  2.48s/it]  0%|          | 148/99918 [07:18<67:34:16,  2.44s/it]  0%|          | 149/99918 [07:20<67:46:12,  2.45s/it]  0%|          | 150/99918 [07:22<67:55:13,  2.45s/it]                                                        0%|          | 150/99918 [07:22<67:55:13,  2.45s/it]  0%|          | 151/99918 [07:25<68:41:55,  2.48s/it]  0%|          | 152/99918 [07:28<70:42:51,  2.55s/it]  0%|          | 153/99918 [07:30<68:31:19,  2.47s/it]  0%|          | 154/99918 [07:33<70:22:23,  2.54s/it]  0%|          | 155/99918 [07:35<68:40:30,  2.48s/it]  0%|          | 156/99918 [07:38<70:08:53,  2.53s/it]  0%|          | 157/99918 [07:40<68:51:25,  2.48s/it]  0%|          | 158/99918 [07:43<69:23:28,  2.50s/it]  0%|          | 159/99918 [07:45<68:20:44,  2.47s/it]  0%|          | 160/99918 [07:46<59:37:38,  2.15s/it]                                                        0%|          | 160/99918 [07:46<59:37:38,  2.15s/it]  0%|          | 161/99918 [07:49<60:44:12,  2.19s/it]  0%|          | 162/99918 [07:52<66:35:33,  2.40s/it]  0%|          | 163/99918 [07:54<67:28:26,  2.44s/it]  0%|          | 164/99918 [07:56<63:57:57,  2.31s/it]  0%|          | 165/99918 [07:58<56:14:06,  2.03s/it]  0%|          | 166/99918 [08:00<59:47:17,  2.16s/it]  0%|          | 167/99918 [08:03<64:38:22,  2.33s/it]  0%|          | 168/99918 [08:05<66:20:38,  2.39s/it]  0%|          | 169/99918 [08:08<68:45:14,  2.48s/it]  0%|          | 170/99918 [08:12<78:44:27,  2.84s/it]                                                        0%|          | 170/99918 [08:12<78:44:27,  2.84s/it]  0%|          | 171/99918 [08:14<77:56:36,  2.81s/it]  0%|          | 172/99918 [08:17<74:08:27,  2.68s/it]  0%|          | 173/99918 [08:18<63:36:46,  2.30s/it]  0%|          | 174/99918 [08:19<55:01:39,  1.99s/it]  0%|          | 175/99918 [08:21<54:30:51,  1.97s/it]  0%|          | 176/99918 [08:25<66:40:09,  2.41s/it]  0%|          | 177/99918 [08:27<68:46:10,  2.48s/it]  0%|          | 178/99918 [08:30<70:43:21,  2.55s/it]  0%|          | 179/99918 [08:33<69:06:05,  2.49s/it]  0%|          | 180/99918 [08:35<73:13:42,  2.64s/it]                                                        0%|          | 180/99918 [08:35<73:13:42,  2.64s/it]  0%|          | 181/99918 [08:37<62:06:51,  2.24s/it]  0%|          | 182/99918 [08:41<74:51:10,  2.70s/it]  0%|          | 183/99918 [08:43<72:48:15,  2.63s/it]  0%|          | 184/99918 [08:46<71:56:06,  2.60s/it]  0%|          | 185/99918 [08:49<81:31:50,  2.94s/it]  0%|          | 186/99918 [08:53<90:46:11,  3.28s/it]  0%|          | 187/99918 [08:56<84:02:34,  3.03s/it]  0%|          | 188/99918 [08:58<75:22:00,  2.72s/it]  0%|          | 189/99918 [09:00<72:24:28,  2.61s/it]  0%|          | 190/99918 [09:02<66:56:28,  2.42s/it]                                                        0%|          | 190/99918 [09:02<66:56:28,  2.42s/it]  0%|          | 191/99918 [09:05<69:34:14,  2.51s/it]  0%|          | 192/99918 [09:08<76:37:41,  2.77s/it]  0%|          | 193/99918 [09:11<73:02:39,  2.64s/it]  0%|          | 194/99918 [09:13<72:29:54,  2.62s/it]  0%|          | 195/99918 [09:15<62:31:45,  2.26s/it]  0%|          | 196/99918 [09:17<68:14:00,  2.46s/it]  0%|          | 197/99918 [09:20<69:40:50,  2.52s/it]  0%|          | 198/99918 [09:22<68:17:18,  2.47s/it]  0%|          | 199/99918 [09:26<72:56:50,  2.63s/it]  0%|          | 200/99918 [09:29<83:15:43,  3.01s/it]                                                        0%|          | 200/99918 [09:29<83:15:43,  3.01s/it][INFO|trainer.py:2937] 2023-09-26 23:55:04,175 >> Saving model checkpoint to /home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-200
  0%|          | 201/99918 [09:32<78:57:21,  2.85s/it]  0%|          | 202/99918 [09:34<74:28:36,  2.69s/it]  0%|          | 203/99918 [09:37<71:45:33,  2.59s/it]  0%|          | 204/99918 [09:39<71:42:17,  2.59s/it]  0%|          | 205/99918 [09:42<70:53:15,  2.56s/it]  0%|          | 206/99918 [09:43<61:42:00,  2.23s/it]  0%|          | 207/99918 [09:45<62:05:31,  2.24s/it]  0%|          | 208/99918 [09:48<65:18:14,  2.36s/it]  0%|          | 209/99918 [09:50<62:39:00,  2.26s/it]  0%|          | 210/99918 [09:53<66:31:22,  2.40s/it]                                                        0%|          | 210/99918 [09:53<66:31:22,  2.40s/it]  0%|          | 211/99918 [09:57<78:32:25,  2.84s/it]  0%|          | 212/99918 [10:00<83:41:56,  3.02s/it]  0%|          | 213/99918 [10:03<82:27:52,  2.98s/it]  0%|          | 214/99918 [10:05<78:13:49,  2.82s/it]  0%|          | 215/99918 [10:10<89:40:31,  3.24s/it]  0%|          | 216/99918 [10:12<81:14:58,  2.93s/it]  0%|          | 217/99918 [10:15<84:37:50,  3.06s/it]  0%|          | 218/99918 [10:17<76:19:38,  2.76s/it]  0%|          | 219/99918 [10:20<73:34:49,  2.66s/it]  0%|          | 220/99918 [10:22<71:58:58,  2.60s/it]                                                        0%|          | 220/99918 [10:22<71:58:58,  2.60s/it]  0%|          | 221/99918 [10:26<79:09:44,  2.86s/it]  0%|          | 222/99918 [10:28<77:59:46,  2.82s/it]  0%|          | 223/99918 [10:30<67:58:24,  2.45s/it]  0%|          | 224/99918 [10:33<70:36:58,  2.55s/it]  0%|          | 225/99918 [10:35<71:45:30,  2.59s/it]  0%|          | 226/99918 [10:37<67:20:55,  2.43s/it]  0%|          | 227/99918 [10:40<67:17:34,  2.43s/it]  0%|          | 228/99918 [10:43<71:30:35,  2.58s/it]  0%|          | 229/99918 [10:44<60:46:59,  2.20s/it]  0%|          | 230/99918 [10:47<65:00:49,  2.35s/it]                                                        0%|          | 230/99918 [10:47<65:00:49,  2.35s/it]  0%|          | 231/99918 [10:51<77:44:09,  2.81s/it]  0%|          | 232/99918 [10:53<71:37:08,  2.59s/it]  0%|          | 233/99918 [10:55<70:21:22,  2.54s/it]  0%|          | 234/99918 [10:58<71:07:58,  2.57s/it]  0%|          | 235/99918 [11:00<71:45:24,  2.59s/it]  0%|          | 236/99918 [11:02<66:35:19,  2.40s/it]  0%|          | 237/99918 [11:05<68:17:07,  2.47s/it]  0%|          | 238/99918 [11:09<82:00:52,  2.96s/it]  0%|          | 239/99918 [11:13<88:54:54,  3.21s/it]  0%|          | 240/99918 [11:15<82:02:08,  2.96s/it]                                                        0%|          | 240/99918 [11:15<82:02:08,  2.96s/it]  0%|          | 241/99918 [11:17<73:48:17,  2.67s/it]  0%|          | 242/99918 [11:20<74:57:52,  2.71s/it]  0%|          | 243/99918 [11:23<72:31:39,  2.62s/it]  0%|          | 244/99918 [11:24<61:50:18,  2.23s/it]  0%|          | 245/99918 [11:28<75:42:54,  2.73s/it]  0%|          | 246/99918 [11:31<77:00:14,  2.78s/it]  0%|          | 247/99918 [11:33<76:28:16,  2.76s/it]  0%|          | 248/99918 [11:36<77:21:55,  2.79s/it]  0%|          | 249/99918 [11:39<77:10:18,  2.79s/it]  0%|          | 250/99918 [11:42<75:50:41,  2.74s/it]                                                        0%|          | 250/99918 [11:42<75:50:41,  2.74s/it]  0%|          | 251/99918 [11:44<71:31:29,  2.58s/it]  0%|          | 252/99918 [11:46<71:05:21,  2.57s/it]  0%|          | 253/99918 [11:49<70:11:13,  2.54s/it]  0%|          | 254/99918 [11:52<71:28:45,  2.58s/it]  0%|          | 255/99918 [11:54<72:36:32,  2.62s/it]  0%|          | 256/99918 [11:57<72:43:03,  2.63s/it]  0%|          | 257/99918 [12:00<72:48:00,  2.63s/it]  0%|          | 258/99918 [12:01<63:11:22,  2.28s/it]  0%|          | 259/99918 [12:03<60:41:58,  2.19s/it]  0%|          | 260/99918 [12:04<52:53:23,  1.91s/it]                                                        0%|          | 260/99918 [12:04<52:53:23,  1.91s/it]  0%|          | 261/99918 [12:08<69:06:02,  2.50s/it]  0%|          | 262/99918 [12:09<59:14:47,  2.14s/it]  0%|          | 263/99918 [12:12<65:43:01,  2.37s/it]  0%|          | 264/99918 [12:15<67:09:15,  2.43s/it]  0%|          | 265/99918 [12:17<68:45:39,  2.48s/it]  0%|          | 266/99918 [12:20<71:28:03,  2.58s/it]  0%|          | 267/99918 [12:22<65:16:17,  2.36s/it]  0%|          | 268/99918 [12:26<75:10:41,  2.72s/it]  0%|          | 269/99918 [12:28<74:12:55,  2.68s/it]  0%|          | 270/99918 [12:31<74:24:59,  2.69s/it]                                                        0%|          | 270/99918 [12:31<74:24:59,  2.69s/it]  0%|          | 271/99918 [12:33<72:33:29,  2.62s/it]  0%|          | 272/99918 [12:36<71:32:08,  2.58s/it]  0%|          | 273/99918 [12:39<78:14:29,  2.83s/it]  0%|          | 274/99918 [12:42<75:37:18,  2.73s/it]  0%|          | 275/99918 [12:45<75:14:10,  2.72s/it]  0%|          | 276/99918 [12:47<74:54:11,  2.71s/it]  0%|          | 277/99918 [12:50<72:51:22,  2.63s/it]  0%|          | 278/99918 [12:53<74:42:21,  2.70s/it]  0%|          | 279/99918 [12:55<71:02:13,  2.57s/it]  0%|          | 280/99918 [12:57<72:00:29,  2.60s/it]                                                        0%|          | 280/99918 [12:57<72:00:29,  2.60s/it]  0%|          | 281/99918 [13:00<71:38:42,  2.59s/it]  0%|          | 282/99918 [13:03<78:19:04,  2.83s/it]  0%|          | 283/99918 [13:06<74:55:39,  2.71s/it]  0%|          | 284/99918 [13:09<80:10:56,  2.90s/it]  0%|          | 285/99918 [13:12<78:31:53,  2.84s/it]  0%|          | 286/99918 [13:14<75:21:15,  2.72s/it]  0%|          | 287/99918 [13:17<72:19:08,  2.61s/it]  0%|          | 288/99918 [13:19<68:28:05,  2.47s/it]  0%|          | 289/99918 [13:21<66:05:31,  2.39s/it]  0%|          | 290/99918 [13:23<66:03:28,  2.39s/it]                                                        0%|          | 290/99918 [13:23<66:03:28,  2.39s/it]  0%|          | 291/99918 [13:26<70:02:08,  2.53s/it]  0%|          | 292/99918 [13:30<78:33:32,  2.84s/it]  0%|          | 293/99918 [13:32<76:46:53,  2.77s/it]  0%|          | 294/99918 [13:35<73:44:39,  2.66s/it]  0%|          | 295/99918 [13:38<75:21:13,  2.72s/it]  0%|          | 296/99918 [13:40<71:36:33,  2.59s/it]  0%|          | 297/99918 [13:41<61:56:10,  2.24s/it]  0%|          | 298/99918 [13:44<63:24:09,  2.29s/it]  0%|          | 299/99918 [13:46<66:23:29,  2.40s/it]  0%|          | 300/99918 [13:50<75:04:51,  2.71s/it]                                                        0%|          | 300/99918 [13:50<75:04:51,  2.71s/it][INFO|trainer.py:2937] 2023-09-26 23:59:24,721 >> Saving model checkpoint to /home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-300
[INFO|trainer.py:3024] 2023-09-26 23:59:24,946 >> Deleting older checkpoint [/home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-100] due to args.save_total_limit
  0%|          | 301/99918 [13:53<75:51:18,  2.74s/it]  0%|          | 302/99918 [13:56<83:34:30,  3.02s/it]  0%|          | 303/99918 [13:59<78:35:34,  2.84s/it]  0%|          | 304/99918 [14:02<85:20:13,  3.08s/it]  0%|          | 305/99918 [14:05<78:27:47,  2.84s/it]  0%|          | 306/99918 [14:07<76:53:58,  2.78s/it]  0%|          | 307/99918 [14:10<77:29:40,  2.80s/it]  0%|          | 308/99918 [14:14<81:47:44,  2.96s/it]  0%|          | 309/99918 [14:17<89:25:53,  3.23s/it]  0%|          | 310/99918 [14:20<82:11:17,  2.97s/it]                                                        0%|          | 310/99918 [14:20<82:11:17,  2.97s/it]  0%|          | 311/99918 [14:22<76:33:38,  2.77s/it]  0%|          | 312/99918 [14:25<74:09:18,  2.68s/it]  0%|          | 313/99918 [14:27<71:52:13,  2.60s/it]  0%|          | 314/99918 [14:31<83:20:12,  3.01s/it]  0%|          | 315/99918 [14:32<70:31:48,  2.55s/it]  0%|          | 316/99918 [14:36<82:29:47,  2.98s/it]  0%|          | 317/99918 [14:39<76:28:28,  2.76s/it]  0%|          | 318/99918 [14:41<76:51:39,  2.78s/it]  0%|          | 319/99918 [14:44<75:42:15,  2.74s/it]  0%|          | 320/99918 [14:48<85:35:48,  3.09s/it]                                                        0%|          | 320/99918 [14:48<85:35:48,  3.09s/it]  0%|          | 321/99918 [14:52<92:10:09,  3.33s/it]  0%|          | 322/99918 [14:54<84:21:28,  3.05s/it]  0%|          | 323/99918 [14:57<79:49:51,  2.89s/it]  0%|          | 324/99918 [15:00<78:31:57,  2.84s/it]  0%|          | 325/99918 [15:03<82:42:15,  2.99s/it]  0%|          | 326/99918 [15:05<77:43:44,  2.81s/it]  0%|          | 327/99918 [15:09<82:22:49,  2.98s/it]  0%|          | 328/99918 [15:11<77:15:55,  2.79s/it]  0%|          | 329/99918 [15:13<73:11:06,  2.65s/it]  0%|          | 330/99918 [15:16<71:26:54,  2.58s/it]                                                        0%|          | 330/99918 [15:16<71:26:54,  2.58s/it]  0%|          | 331/99918 [15:18<71:47:45,  2.60s/it]  0%|          | 332/99918 [15:21<71:43:11,  2.59s/it]  0%|          | 333/99918 [15:24<71:29:02,  2.58s/it]  0%|          | 334/99918 [15:26<70:32:29,  2.55s/it]  0%|          | 335/99918 [15:29<71:39:41,  2.59s/it]  0%|          | 336/99918 [15:31<71:45:46,  2.59s/it]  0%|          | 337/99918 [15:34<70:34:27,  2.55s/it]  0%|          | 338/99918 [15:37<76:24:56,  2.76s/it]  0%|          | 339/99918 [15:40<75:16:31,  2.72s/it]  0%|          | 340/99918 [15:42<73:45:06,  2.67s/it]                                                        0%|          | 340/99918 [15:42<73:45:06,  2.67s/it]  0%|          | 341/99918 [15:45<78:28:08,  2.84s/it]  0%|          | 342/99918 [15:48<79:28:50,  2.87s/it]  0%|          | 343/99918 [15:52<85:25:49,  3.09s/it]  0%|          | 344/99918 [15:54<80:27:21,  2.91s/it]  0%|          | 345/99918 [15:57<76:43:45,  2.77s/it]  0%|          | 346/99918 [16:00<82:12:04,  2.97s/it]  0%|          | 347/99918 [16:03<79:15:08,  2.87s/it]  0%|          | 348/99918 [16:05<71:58:11,  2.60s/it]  0%|          | 349/99918 [16:08<72:34:21,  2.62s/it]  0%|          | 350/99918 [16:11<76:07:34,  2.75s/it]                                                        0%|          | 350/99918 [16:11<76:07:34,  2.75s/it]  0%|          | 351/99918 [16:13<71:34:14,  2.59s/it]  0%|          | 352/99918 [16:15<70:41:45,  2.56s/it]  0%|          | 353/99918 [16:19<78:52:48,  2.85s/it]  0%|          | 354/99918 [16:22<77:23:55,  2.80s/it]  0%|          | 355/99918 [16:24<73:04:18,  2.64s/it]  0%|          | 356/99918 [16:27<73:23:41,  2.65s/it]  0%|          | 357/99918 [16:28<67:22:18,  2.44s/it]  0%|          | 358/99918 [16:31<67:39:11,  2.45s/it]  0%|          | 359/99918 [16:33<61:37:16,  2.23s/it]  0%|          | 360/99918 [16:35<63:41:06,  2.30s/it]                                                        0%|          | 360/99918 [16:35<63:41:06,  2.30s/it]  0%|          | 361/99918 [16:37<57:31:00,  2.08s/it]  0%|          | 362/99918 [16:40<67:46:05,  2.45s/it]  0%|          | 363/99918 [16:44<79:11:15,  2.86s/it]  0%|          | 364/99918 [16:46<76:02:05,  2.75s/it]  0%|          | 365/99918 [16:49<78:28:34,  2.84s/it]  0%|          | 366/99918 [16:53<85:58:17,  3.11s/it]  0%|          | 367/99918 [16:56<81:52:41,  2.96s/it]  0%|          | 368/99918 [16:59<84:40:37,  3.06s/it]  0%|          | 369/99918 [17:03<91:26:59,  3.31s/it]  0%|          | 370/99918 [17:05<84:24:04,  3.05s/it]                                                        0%|          | 370/99918 [17:05<84:24:04,  3.05s/it]  0%|          | 371/99918 [17:08<78:41:44,  2.85s/it]  0%|          | 372/99918 [17:11<86:15:41,  3.12s/it]  0%|          | 373/99918 [17:15<86:20:45,  3.12s/it]  0%|          | 374/99918 [17:17<82:35:55,  2.99s/it]  0%|          | 375/99918 [17:19<69:13:21,  2.50s/it]  0%|          | 376/99918 [17:22<73:06:37,  2.64s/it]  0%|          | 377/99918 [17:24<74:09:06,  2.68s/it]  0%|          | 378/99918 [17:28<83:04:37,  3.00s/it]  0%|          | 379/99918 [17:31<78:44:57,  2.85s/it]  0%|          | 380/99918 [17:32<65:27:09,  2.37s/it]                                                        0%|          | 380/99918 [17:32<65:27:09,  2.37s/it]  0%|          | 381/99918 [17:34<62:31:55,  2.26s/it]  0%|          | 382/99918 [17:36<63:07:27,  2.28s/it]  0%|          | 383/99918 [17:40<76:34:56,  2.77s/it]  0%|          | 384/99918 [17:42<73:20:52,  2.65s/it]  0%|          | 385/99918 [17:45<72:07:27,  2.61s/it]  0%|          | 386/99918 [17:48<76:04:27,  2.75s/it]  0%|          | 387/99918 [17:51<73:57:09,  2.67s/it]  0%|          | 388/99918 [17:53<72:46:10,  2.63s/it]  0%|          | 389/99918 [17:56<72:09:53,  2.61s/it]  0%|          | 390/99918 [17:58<69:33:47,  2.52s/it]                                                        0%|          | 390/99918 [17:58<69:33:47,  2.52s/it]  0%|          | 391/99918 [18:01<71:11:26,  2.58s/it]  0%|          | 392/99918 [18:04<77:29:13,  2.80s/it]  0%|          | 393/99918 [18:06<71:10:30,  2.57s/it]  0%|          | 394/99918 [18:08<69:10:44,  2.50s/it]  0%|          | 395/99918 [18:11<70:30:40,  2.55s/it]  0%|          | 396/99918 [18:14<74:57:16,  2.71s/it]  0%|          | 397/99918 [18:18<85:51:43,  3.11s/it]  0%|          | 398/99918 [18:22<94:13:59,  3.41s/it]  0%|          | 399/99918 [18:25<86:56:01,  3.14s/it]  0%|          | 400/99918 [18:27<81:45:16,  2.96s/it]                                                        0%|          | 400/99918 [18:27<81:45:16,  2.96s/it][INFO|trainer.py:2937] 2023-09-27 00:04:02,116 >> Saving model checkpoint to /home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-400
[INFO|trainer.py:3024] 2023-09-27 00:04:02,343 >> Deleting older checkpoint [/home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-200] due to args.save_total_limit
  0%|          | 401/99918 [18:30<80:31:24,  2.91s/it]  0%|          | 402/99918 [18:32<75:53:56,  2.75s/it]  0%|          | 403/99918 [18:35<75:06:16,  2.72s/it]  0%|          | 404/99918 [18:38<72:37:48,  2.63s/it]  0%|          | 405/99918 [18:40<71:38:01,  2.59s/it]  0%|          | 406/99918 [18:43<77:46:43,  2.81s/it]  0%|          | 407/99918 [18:46<73:48:27,  2.67s/it]  0%|          | 408/99918 [18:48<73:41:09,  2.67s/it]  0%|          | 409/99918 [18:51<72:19:17,  2.62s/it]  0%|          | 410/99918 [18:55<84:13:37,  3.05s/it]                                                        0%|          | 410/99918 [18:55<84:13:37,  3.05s/it]  0%|          | 411/99918 [18:57<79:46:10,  2.89s/it]  0%|          | 412/99918 [19:00<77:19:12,  2.80s/it]  0%|          | 413/99918 [19:01<66:01:23,  2.39s/it]  0%|          | 414/99918 [19:04<66:32:43,  2.41s/it]  0%|          | 415/99918 [19:06<66:28:56,  2.41s/it]  0%|          | 416/99918 [19:10<75:52:22,  2.75s/it]  0%|          | 417/99918 [19:13<79:24:34,  2.87s/it]  0%|          | 418/99918 [19:15<75:35:31,  2.73s/it]  0%|          | 419/99918 [19:18<72:24:32,  2.62s/it]  0%|          | 420/99918 [19:20<70:18:26,  2.54s/it]                                                        0%|          | 420/99918 [19:20<70:18:26,  2.54s/it]  0%|          | 421/99918 [19:23<70:07:44,  2.54s/it]  0%|          | 422/99918 [19:27<82:11:43,  2.97s/it]  0%|          | 423/99918 [19:29<80:21:23,  2.91s/it]  0%|          | 424/99918 [19:33<85:03:26,  3.08s/it]  0%|          | 425/99918 [19:36<83:50:54,  3.03s/it]  0%|          | 426/99918 [19:40<90:18:17,  3.27s/it]  0%|          | 427/99918 [19:43<87:05:35,  3.15s/it]  0%|          | 428/99918 [19:45<83:33:13,  3.02s/it]  0%|          | 429/99918 [19:49<91:05:38,  3.30s/it]  0%|          | 430/99918 [19:53<95:02:36,  3.44s/it]                                                        0%|          | 430/99918 [19:53<95:02:36,  3.44s/it]  0%|          | 431/99918 [19:55<79:30:42,  2.88s/it]  0%|          | 432/99918 [19:57<77:36:09,  2.81s/it]  0%|          | 433/99918 [20:00<78:49:19,  2.85s/it]  0%|          | 434/99918 [20:03<75:37:34,  2.74s/it]  0%|          | 435/99918 [20:06<82:06:50,  2.97s/it]  0%|          | 436/99918 [20:10<92:39:12,  3.35s/it]  0%|          | 437/99918 [20:14<93:19:01,  3.38s/it]  0%|          | 438/99918 [20:16<85:19:54,  3.09s/it]  0%|          | 439/99918 [20:19<81:31:33,  2.95s/it]  0%|          | 440/99918 [20:22<85:15:49,  3.09s/it]                                                        0%|          | 440/99918 [20:22<85:15:49,  3.09s/it]  0%|          | 441/99918 [20:26<93:01:58,  3.37s/it]  0%|          | 442/99918 [20:29<85:29:07,  3.09s/it]  0%|          | 443/99918 [20:31<77:11:39,  2.79s/it]  0%|          | 444/99918 [20:33<74:39:36,  2.70s/it]  0%|          | 445/99918 [20:37<84:46:07,  3.07s/it]  0%|          | 446/99918 [20:39<70:38:10,  2.56s/it]  0%|          | 447/99918 [20:41<68:23:22,  2.48s/it]  0%|          | 448/99918 [20:45<81:14:53,  2.94s/it]  0%|          | 449/99918 [20:47<77:21:02,  2.80s/it]  0%|          | 450/99918 [20:50<77:15:15,  2.80s/it]                                                        0%|          | 450/99918 [20:50<77:15:15,  2.80s/it]  0%|          | 451/99918 [20:54<83:16:04,  3.01s/it]  0%|          | 452/99918 [20:56<80:25:36,  2.91s/it]  0%|          | 453/99918 [20:59<76:31:20,  2.77s/it]  0%|          | 454/99918 [21:01<74:18:03,  2.69s/it]  0%|          | 455/99918 [21:05<79:22:05,  2.87s/it]  0%|          | 456/99918 [21:08<85:58:02,  3.11s/it]  0%|          | 457/99918 [21:12<89:15:10,  3.23s/it]  0%|          | 458/99918 [21:15<85:44:54,  3.10s/it]  0%|          | 459/99918 [21:17<81:46:44,  2.96s/it]  0%|          | 460/99918 [21:19<73:44:04,  2.67s/it]                                                        0%|          | 460/99918 [21:19<73:44:04,  2.67s/it]  0%|          | 461/99918 [21:21<68:31:34,  2.48s/it]  0%|          | 462/99918 [21:24<66:48:14,  2.42s/it]  0%|          | 463/99918 [21:26<66:01:51,  2.39s/it]  0%|          | 464/99918 [21:28<66:32:13,  2.41s/it]  0%|          | 465/99918 [21:31<68:18:20,  2.47s/it]  0%|          | 466/99918 [21:33<67:34:12,  2.45s/it]  0%|          | 467/99918 [21:36<69:05:33,  2.50s/it]  0%|          | 468/99918 [21:38<68:42:40,  2.49s/it]  0%|          | 469/99918 [21:42<76:06:01,  2.75s/it]  0%|          | 470/99918 [21:44<71:17:29,  2.58s/it]                                                        0%|          | 470/99918 [21:44<71:17:29,  2.58s/it]  0%|          | 471/99918 [21:48<80:42:32,  2.92s/it]  0%|          | 472/99918 [21:50<77:37:03,  2.81s/it]  0%|          | 473/99918 [21:53<75:00:03,  2.72s/it]  0%|          | 474/99918 [21:55<73:21:48,  2.66s/it]  0%|          | 475/99918 [21:57<63:02:41,  2.28s/it]  0%|          | 476/99918 [22:00<71:28:15,  2.59s/it]  0%|          | 477/99918 [22:03<72:13:55,  2.61s/it]  0%|          | 478/99918 [22:05<70:38:57,  2.56s/it]  0%|          | 479/99918 [22:08<72:57:14,  2.64s/it]  0%|          | 480/99918 [22:11<78:46:50,  2.85s/it]                                                        0%|          | 480/99918 [22:11<78:46:50,  2.85s/it]  0%|          | 481/99918 [22:15<87:02:52,  3.15s/it]  0%|          | 482/99918 [22:18<88:59:03,  3.22s/it]  0%|          | 483/99918 [22:23<99:26:11,  3.60s/it]  0%|          | 484/99918 [22:26<93:52:23,  3.40s/it]  0%|          | 485/99918 [22:27<79:13:12,  2.87s/it]  0%|          | 486/99918 [22:29<67:45:49,  2.45s/it]  0%|          | 487/99918 [22:30<59:54:01,  2.17s/it]  0%|          | 488/99918 [22:32<54:15:41,  1.96s/it]  0%|          | 489/99918 [22:33<50:16:31,  1.82s/it]  0%|          | 490/99918 [22:35<48:04:48,  1.74s/it]                                                        0%|          | 490/99918 [22:35<48:04:48,  1.74s/it]  0%|          | 491/99918 [22:36<45:57:45,  1.66s/it]  0%|          | 492/99918 [22:38<47:43:29,  1.73s/it]  0%|          | 493/99918 [22:40<44:51:24,  1.62s/it]  0%|          | 494/99918 [22:41<42:40:44,  1.55s/it]  0%|          | 495/99918 [22:43<42:35:58,  1.54s/it]  0%|          | 496/99918 [22:45<47:25:07,  1.72s/it]  0%|          | 497/99918 [22:47<47:53:39,  1.73s/it]  0%|          | 498/99918 [22:48<44:48:53,  1.62s/it]  0%|          | 499/99918 [22:51<54:51:49,  1.99s/it]  1%|          | 500/99918 [22:53<57:28:54,  2.08s/it]                                                        1%|          | 500/99918 [22:53<57:28:54,  2.08s/it][INFO|trainer.py:2937] 2023-09-27 00:08:27,823 >> Saving model checkpoint to /home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-500
[INFO|trainer.py:3024] 2023-09-27 00:08:28,055 >> Deleting older checkpoint [/home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-300] due to args.save_total_limit
  1%|          | 501/99918 [22:55<55:48:51,  2.02s/it]  1%|          | 502/99918 [22:57<54:18:59,  1.97s/it]  1%|          | 503/99918 [22:58<51:04:13,  1.85s/it]  1%|          | 504/99918 [23:00<47:49:23,  1.73s/it]  1%|          | 505/99918 [23:01<46:02:58,  1.67s/it]  1%|          | 506/99918 [23:03<44:09:39,  1.60s/it]  1%|          | 507/99918 [23:06<56:07:44,  2.03s/it]  1%|          | 508/99918 [23:08<53:57:02,  1.95s/it]  1%|          | 509/99918 [23:09<49:16:17,  1.78s/it]  1%|          | 510/99918 [23:11<51:16:27,  1.86s/it]                                                        1%|          | 510/99918 [23:11<51:16:27,  1.86s/it]  1%|          | 511/99918 [23:12<48:30:36,  1.76s/it]  1%|          | 512/99918 [23:14<46:09:28,  1.67s/it]  1%|          | 513/99918 [23:16<49:05:52,  1.78s/it]  1%|          | 514/99918 [23:17<45:31:31,  1.65s/it]  1%|          | 515/99918 [23:19<45:32:34,  1.65s/it]  1%|          | 516/99918 [23:21<45:39:03,  1.65s/it]  1%|          | 517/99918 [23:22<44:29:42,  1.61s/it]  1%|          | 518/99918 [23:25<53:09:11,  1.93s/it]  1%|          | 519/99918 [23:27<54:49:51,  1.99s/it]  1%|          | 520/99918 [23:29<54:24:57,  1.97s/it]                                                        1%|          | 520/99918 [23:29<54:24:57,  1.97s/it]  1%|          | 521/99918 [23:30<49:10:31,  1.78s/it]  1%|          | 522/99918 [23:32<48:51:37,  1.77s/it]  1%|          | 523/99918 [23:34<47:06:16,  1.71s/it]  1%|          | 524/99918 [23:35<45:24:56,  1.64s/it]  1%|          | 525/99918 [23:38<54:53:41,  1.99s/it]  1%|          | 526/99918 [23:40<53:08:13,  1.92s/it]  1%|          | 527/99918 [23:41<51:23:28,  1.86s/it]  1%|          | 528/99918 [23:44<60:27:53,  2.19s/it]  1%|          | 529/99918 [23:46<55:11:15,  2.00s/it]  1%|          | 530/99918 [23:48<56:08:07,  2.03s/it]                                                        1%|          | 530/99918 [23:48<56:08:07,  2.03s/it]  1%|          | 531/99918 [23:49<51:48:49,  1.88s/it]  1%|          | 532/99918 [23:51<49:11:11,  1.78s/it]  1%|          | 533/99918 [23:53<48:41:35,  1.76s/it]  1%|          | 534/99918 [23:54<47:55:20,  1.74s/it]  1%|          | 535/99918 [23:56<46:16:08,  1.68s/it]  1%|          | 536/99918 [23:58<45:48:40,  1.66s/it]  1%|          | 537/99918 [24:00<48:31:23,  1.76s/it]  1%|          | 538/99918 [24:01<49:24:26,  1.79s/it]  1%|          | 539/99918 [24:03<50:04:52,  1.81s/it]  1%|          | 540/99918 [24:05<48:38:51,  1.76s/it]                                                        1%|          | 540/99918 [24:05<48:38:51,  1.76s/it]  1%|          | 541/99918 [24:07<50:21:55,  1.82s/it]  1%|          | 542/99918 [24:08<47:37:00,  1.72s/it]  1%|          | 543/99918 [24:10<45:55:53,  1.66s/it]  1%|          | 544/99918 [24:12<48:48:52,  1.77s/it]  1%|          | 545/99918 [24:13<45:33:42,  1.65s/it]  1%|          | 546/99918 [24:17<58:54:58,  2.13s/it]  1%|          | 547/99918 [24:19<58:04:55,  2.10s/it]  1%|          | 548/99918 [24:20<54:01:00,  1.96s/it]  1%|          | 549/99918 [24:22<51:55:59,  1.88s/it]  1%|          | 550/99918 [24:25<61:56:54,  2.24s/it]                                                        1%|          | 550/99918 [24:25<61:56:54,  2.24s/it]  1%|          | 551/99918 [24:27<58:24:55,  2.12s/it]  1%|          | 552/99918 [24:28<53:39:48,  1.94s/it]  1%|          | 553/99918 [24:30<50:28:17,  1.83s/it]  1%|          | 554/99918 [24:31<47:43:15,  1.73s/it]  1%|          | 555/99918 [24:33<47:08:58,  1.71s/it]  1%|          | 556/99918 [24:35<47:30:40,  1.72s/it]  1%|          | 557/99918 [24:37<48:54:11,  1.77s/it]  1%|          | 558/99918 [24:39<52:59:59,  1.92s/it]  1%|          | 559/99918 [24:41<51:07:32,  1.85s/it]  1%|          | 560/99918 [24:43<51:16:02,  1.86s/it]                                                        1%|          | 560/99918 [24:43<51:16:02,  1.86s/it]  1%|          | 561/99918 [24:45<52:03:22,  1.89s/it]  1%|          | 562/99918 [24:47<54:19:15,  1.97s/it]  1%|          | 563/99918 [24:49<53:58:01,  1.96s/it]  1%|          | 564/99918 [24:52<61:58:49,  2.25s/it]  1%|          | 565/99918 [24:53<55:48:09,  2.02s/it]  1%|          | 566/99918 [24:55<57:15:37,  2.07s/it]  1%|          | 567/99918 [24:58<63:17:38,  2.29s/it]  1%|          | 568/99918 [25:00<57:07:51,  2.07s/it]  1%|          | 569/99918 [25:01<54:35:22,  1.98s/it]  1%|          | 570/99918 [25:03<50:56:11,  1.85s/it]                                                        1%|          | 570/99918 [25:03<50:56:11,  1.85s/it]  1%|          | 571/99918 [25:04<48:58:17,  1.77s/it]  1%|          | 572/99918 [25:08<59:59:25,  2.17s/it]  1%|          | 573/99918 [25:09<55:02:08,  1.99s/it]  1%|          | 574/99918 [25:11<51:05:37,  1.85s/it]  1%|          | 575/99918 [25:13<51:45:58,  1.88s/it]  1%|          | 576/99918 [25:14<49:24:06,  1.79s/it]  1%|          | 577/99918 [25:16<49:12:55,  1.78s/it]  1%|          | 578/99918 [25:19<57:12:18,  2.07s/it]  1%|          | 579/99918 [25:20<52:44:30,  1.91s/it]  1%|          | 580/99918 [25:23<60:14:08,  2.18s/it]                                                        1%|          | 580/99918 [25:23<60:14:08,  2.18s/it]  1%|          | 581/99918 [25:25<58:58:57,  2.14s/it]  1%|          | 582/99918 [25:27<54:03:17,  1.96s/it]  1%|          | 583/99918 [25:28<52:20:07,  1.90s/it]  1%|          | 584/99918 [25:30<47:59:00,  1.74s/it]  1%|          | 585/99918 [25:31<47:46:24,  1.73s/it]  1%|          | 586/99918 [25:33<46:20:25,  1.68s/it]  1%|          | 587/99918 [25:35<46:57:48,  1.70s/it]  1%|          | 588/99918 [25:37<49:02:46,  1.78s/it]  1%|          | 589/99918 [25:38<47:59:42,  1.74s/it]  1%|          | 590/99918 [25:41<52:51:13,  1.92s/it]                                                        1%|          | 590/99918 [25:41<52:51:13,  1.92s/it]  1%|          | 591/99918 [25:43<54:10:02,  1.96s/it]  1%|          | 592/99918 [25:44<51:13:01,  1.86s/it]  1%|          | 593/99918 [25:46<47:59:35,  1.74s/it]  1%|          | 594/99918 [25:49<57:33:39,  2.09s/it]  1%|          | 595/99918 [25:51<54:57:41,  1.99s/it]  1%|          | 596/99918 [25:52<51:12:43,  1.86s/it]  1%|          | 597/99918 [25:54<48:25:50,  1.76s/it]  1%|          | 598/99918 [25:55<46:22:50,  1.68s/it]  1%|          | 599/99918 [25:57<44:57:34,  1.63s/it]  1%|          | 600/99918 [25:58<42:48:31,  1.55s/it]                                                        1%|          | 600/99918 [25:58<42:48:31,  1.55s/it][INFO|trainer.py:2937] 2023-09-27 00:11:32,763 >> Saving model checkpoint to /home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-600
[INFO|trainer.py:3024] 2023-09-27 00:11:32,998 >> Deleting older checkpoint [/home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-400] due to args.save_total_limit
  1%|          | 601/99918 [26:00<43:41:34,  1.58s/it]  1%|          | 602/99918 [26:01<43:05:58,  1.56s/it]  1%|          | 603/99918 [26:03<49:09:46,  1.78s/it]  1%|          | 604/99918 [26:05<46:51:56,  1.70s/it]  1%|          | 605/99918 [26:06<44:27:30,  1.61s/it]  1%|          | 606/99918 [26:08<47:49:29,  1.73s/it]  1%|          | 607/99918 [26:10<45:15:42,  1.64s/it]  1%|          | 608/99918 [26:11<44:01:43,  1.60s/it]  1%|          | 609/99918 [26:13<43:12:23,  1.57s/it]  1%|          | 610/99918 [26:15<46:32:20,  1.69s/it]                                                        1%|          | 610/99918 [26:15<46:32:20,  1.69s/it]  1%|          | 611/99918 [26:16<45:14:41,  1.64s/it]  1%|          | 612/99918 [26:18<43:47:20,  1.59s/it]  1%|          | 613/99918 [26:20<48:46:53,  1.77s/it]  1%|          | 614/99918 [26:22<47:44:51,  1.73s/it]  1%|          | 615/99918 [26:23<47:24:37,  1.72s/it]  1%|          | 616/99918 [26:25<46:44:41,  1.69s/it]  1%|          | 617/99918 [26:26<45:21:58,  1.64s/it]  1%|          | 618/99918 [26:28<46:27:13,  1.68s/it]  1%|          | 619/99918 [26:30<46:52:17,  1.70s/it]  1%|          | 620/99918 [26:32<47:04:44,  1.71s/it]                                                        1%|          | 620/99918 [26:32<47:04:44,  1.71s/it]  1%|          | 621/99918 [26:35<56:21:01,  2.04s/it]  1%|          | 622/99918 [26:36<53:20:43,  1.93s/it]  1%|          | 623/99918 [26:38<49:43:28,  1.80s/it]  1%|          | 624/99918 [26:39<47:03:17,  1.71s/it]  1%|          | 625/99918 [26:41<47:43:05,  1.73s/it]  1%|          | 626/99918 [26:43<47:28:15,  1.72s/it]  1%|          | 627/99918 [26:44<48:32:19,  1.76s/it]  1%|          | 628/99918 [26:48<61:37:48,  2.23s/it]  1%|          | 629/99918 [26:50<57:37:30,  2.09s/it]  1%|          | 630/99918 [26:51<51:37:17,  1.87s/it]                                                        1%|          | 630/99918 [26:51<51:37:17,  1.87s/it]  1%|          | 631/99918 [26:53<49:19:36,  1.79s/it]  1%|          | 632/99918 [26:54<47:38:08,  1.73s/it]  1%|          | 633/99918 [26:55<44:39:19,  1.62s/it]  1%|          | 634/99918 [26:57<43:43:43,  1.59s/it]  1%|          | 635/99918 [26:59<43:14:36,  1.57s/it]  1%|          | 636/99918 [27:00<42:06:01,  1.53s/it]  1%|          | 637/99918 [27:01<42:00:58,  1.52s/it]  1%|          | 638/99918 [27:03<40:38:36,  1.47s/it]  1%|          | 639/99918 [27:04<38:57:13,  1.41s/it]  1%|          | 640/99918 [27:05<38:45:19,  1.41s/it]                                                        1%|          | 640/99918 [27:05<38:45:19,  1.41s/it]  1%|          | 641/99918 [27:08<51:45:00,  1.88s/it]  1%|          | 642/99918 [27:11<54:12:54,  1.97s/it]  1%|          | 643/99918 [27:12<50:01:08,  1.81s/it]  1%|          | 644/99918 [27:13<46:25:05,  1.68s/it]  1%|          | 645/99918 [27:15<46:37:20,  1.69s/it]  1%|          | 646/99918 [27:17<48:37:12,  1.76s/it]  1%|          | 647/99918 [27:19<48:47:22,  1.77s/it]  1%|          | 648/99918 [27:21<48:57:38,  1.78s/it]  1%|          | 649/99918 [27:22<46:45:47,  1.70s/it]  1%|          | 650/99918 [27:24<44:57:53,  1.63s/it]                                                        1%|          | 650/99918 [27:24<44:57:53,  1.63s/it]  1%|          | 651/99918 [27:25<46:08:10,  1.67s/it]  1%|          | 652/99918 [27:28<49:47:52,  1.81s/it]  1%|          | 653/99918 [27:29<48:48:03,  1.77s/it]  1%|          | 654/99918 [27:31<51:17:54,  1.86s/it]  1%|          | 655/99918 [27:33<49:09:38,  1.78s/it]  1%|          | 656/99918 [27:35<48:58:45,  1.78s/it]  1%|          | 657/99918 [27:36<47:29:36,  1.72s/it]  1%|          | 658/99918 [27:38<46:15:35,  1.68s/it]  1%|          | 659/99918 [27:39<44:19:13,  1.61s/it]  1%|          | 660/99918 [27:41<43:35:00,  1.58s/it]                                                        1%|          | 660/99918 [27:41<43:35:00,  1.58s/it]  1%|          | 661/99918 [27:43<49:07:06,  1.78s/it]  1%|          | 662/99918 [27:45<47:06:04,  1.71s/it]  1%|          | 663/99918 [27:46<44:01:19,  1.60s/it]  1%|          | 664/99918 [27:48<45:13:31,  1.64s/it]  1%|          | 665/99918 [27:50<47:22:13,  1.72s/it]  1%|          | 666/99918 [27:51<45:35:36,  1.65s/it]  1%|          | 667/99918 [27:53<45:23:26,  1.65s/it]  1%|          | 668/99918 [27:54<42:49:59,  1.55s/it]  1%|          | 669/99918 [27:56<43:27:52,  1.58s/it]  1%|          | 670/99918 [27:57<44:49:06,  1.63s/it]                                                        1%|          | 670/99918 [27:57<44:49:06,  1.63s/it]  1%|          | 671/99918 [27:59<45:48:36,  1.66s/it]  1%|          | 672/99918 [28:01<44:31:02,  1.61s/it]  1%|          | 673/99918 [28:02<44:02:07,  1.60s/it]  1%|          | 674/99918 [28:05<54:39:04,  1.98s/it]  1%|          | 675/99918 [28:07<51:26:16,  1.87s/it]  1%|          | 676/99918 [28:08<50:41:20,  1.84s/it]  1%|          | 677/99918 [28:10<49:26:18,  1.79s/it]  1%|          | 678/99918 [28:12<51:16:44,  1.86s/it]  1%|          | 679/99918 [28:14<53:38:20,  1.95s/it]  1%|          | 680/99918 [28:16<51:14:30,  1.86s/it]                                                        1%|          | 680/99918 [28:16<51:14:30,  1.86s/it]  1%|          | 681/99918 [28:17<47:20:21,  1.72s/it]  1%|          | 682/99918 [28:19<45:24:50,  1.65s/it]  1%|          | 683/99918 [28:20<44:26:24,  1.61s/it]  1%|          | 684/99918 [28:22<43:21:57,  1.57s/it]  1%|          | 685/99918 [28:23<42:42:17,  1.55s/it]  1%|          | 686/99918 [28:25<44:59:24,  1.63s/it]  1%|          | 687/99918 [28:27<49:52:33,  1.81s/it]  1%|          | 688/99918 [28:29<48:39:21,  1.77s/it]  1%|          | 689/99918 [28:31<47:21:04,  1.72s/it]  1%|          | 690/99918 [28:32<46:03:17,  1.67s/it]                                                        1%|          | 690/99918 [28:32<46:03:17,  1.67s/it]  1%|          | 691/99918 [28:34<47:02:30,  1.71s/it]  1%|          | 692/99918 [28:36<45:37:55,  1.66s/it]  1%|          | 693/99918 [28:38<49:29:44,  1.80s/it]  1%|          | 694/99918 [28:40<50:46:39,  1.84s/it]  1%|          | 695/99918 [28:41<48:26:36,  1.76s/it]  1%|          | 696/99918 [28:43<49:15:37,  1.79s/it]  1%|          | 697/99918 [28:45<46:39:12,  1.69s/it]  1%|          | 698/99918 [28:46<48:32:07,  1.76s/it]  1%|          | 699/99918 [28:49<57:13:17,  2.08s/it]  1%|          | 700/99918 [28:51<53:14:41,  1.93s/it]                                                        1%|          | 700/99918 [28:51<53:14:41,  1.93s/it][INFO|trainer.py:2937] 2023-09-27 00:14:25,655 >> Saving model checkpoint to /home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-700
[INFO|trainer.py:3024] 2023-09-27 00:14:25,884 >> Deleting older checkpoint [/home/u131168/mh_one_api/model/ft_models/flan-t5-xl_peft_finetuned_model1/checkpoint-500] due to args.save_total_limit
  1%|          | 701/99918 [28:53<54:57:20,  1.99s/it]  1%|          | 702/99918 [28:56<61:21:58,  2.23s/it]  1%|          | 703/99918 [28:59<66:13:06,  2.40s/it]  1%|          | 704/99918 [29:01<62:59:35,  2.29s/it]  1%|          | 705/99918 [29:02<58:28:51,  2.12s/it]  1%|          | 706/99918 [29:04<53:16:19,  1.93s/it]  1%|          | 707/99918 [29:05<49:52:51,  1.81s/it]  1%|          | 708/99918 [29:07<51:42:16,  1.88s/it]  1%|          | 709/99918 [29:09<53:26:45,  1.94s/it]  1%|          | 710/99918 [29:11<51:35:58,  1.87s/it]                                                        1%|          | 710/99918 [29:11<51:35:58,  1.87s/it]  1%|          | 711/99918 [29:13<48:22:34,  1.76s/it]  1%|          | 712/99918 [29:14<48:17:35,  1.75s/it]  1%|          | 713/99918 [29:16<46:14:32,  1.68s/it]  1%|          | 714/99918 [29:19<54:50:09,  1.99s/it]  1%|          | 715/99918 [29:20<48:52:53,  1.77s/it]  1%|          | 716/99918 [29:21<46:41:00,  1.69s/it]  1%|          | 717/99918 [29:23<45:54:34,  1.67s/it]  1%|          | 718/99918 [29:25<47:53:57,  1.74s/it]  1%|          | 719/99918 [29:26<46:32:49,  1.69s/it]  1%|          | 720/99918 [29:28<48:53:39,  1.77s/it]                                                        1%|          | 720/99918 [29:28<48:53:39,  1.77s/it]  1%|          | 721/99918 [29:32<60:49:07,  2.21s/it]  1%|          | 722/99918 [29:33<54:33:12,  1.98s/it]  1%|          | 723/99918 [29:35<54:06:04,  1.96s/it]  1%|          | 724/99918 [29:36<49:17:32,  1.79s/it]  1%|          | 725/99918 [29:38<46:57:23,  1.70s/it]  1%|          | 726/99918 [29:40<46:10:11,  1.68s/it]  1%|          | 727/99918 [29:42<56:33:42,  2.05s/it]  1%|          | 728/99918 [29:44<52:46:59,  1.92s/it]  1%|          | 729/99918 [29:47<60:44:52,  2.20s/it]  1%|          | 730/99918 [29:50<66:29:31,  2.41s/it]                                                        1%|          | 730/99918 [29:50<66:29:31,  2.41s/it]  1%|          | 731/99918 [29:52<60:01:31,  2.18s/it]  1%|          | 732/99918 [29:53<56:31:35,  2.05s/it]  1%|          | 733/99918 [29:56<62:21:26,  2.26s/it]  1%|          | 734/99918 [29:58<56:17:27,  2.04s/it]  1%|          | 735/99918 [30:01<63:55:55,  2.32s/it]  1%|          | 736/99918 [30:02<60:38:26,  2.20s/it]  1%|          | 737/99918 [30:04<59:18:45,  2.15s/it]  1%|          | 738/99918 [30:06<54:22:41,  1.97s/it]  1%|          | 739/99918 [30:08<56:22:02,  2.05s/it]  1%|          | 740/99918 [30:10<52:43:11,  1.91s/it]                                                        1%|          | 740/99918 [30:10<52:43:11,  1.91s/it]  1%|          | 741/99918 [30:11<49:11:13,  1.79s/it]  1%|          | 742/99918 [30:13<47:39:08,  1.73s/it]  1%|          | 743/99918 [30:15<47:50:14,  1.74s/it]  1%|          | 744/99918 [30:16<45:59:43,  1.67s/it]  1%|          | 745/99918 [30:18<48:26:29,  1.76s/it]  1%|          | 746/99918 [30:20<46:38:07,  1.69s/it]  1%|          | 747/99918 [30:21<45:40:29,  1.66s/it]  1%|          | 748/99918 [30:23<50:12:58,  1.82s/it]  1%|          | 749/99918 [30:26<53:00:03,  1.92s/it]  1%|          | 750/99918 [30:27<49:10:09,  1.78s/it]                                                        1%|          | 750/99918 [30:27<49:10:09,  1.78s/it]  1%|          | 751/99918 [30:29<46:28:14,  1.69s/it]  1%|          | 752/99918 [30:31<55:06:00,  2.00s/it]  1%|          | 753/99918 [30:33<53:21:13,  1.94s/it]  1%|          | 754/99918 [30:35<52:11:47,  1.89s/it]  1%|          | 755/99918 [30:36<49:03:27,  1.78s/it]  1%|          | 756/99918 [30:38<51:06:02,  1.86s/it]  1%|          | 757/99918 [30:40<50:33:52,  1.84s/it]  1%|          | 758/99918 [30:42<50:47:57,  1.84s/it]  1%|          | 759/99918 [30:43<46:49:21,  1.70s/it]  1%|          | 760/99918 [30:46<52:04:22,  1.89s/it]                                                        1%|          | 760/99918 [30:46<52:04:22,  1.89s/it]  1%|          | 761/99918 [30:47<48:55:23,  1.78s/it]  1%|          | 762/99918 [30:49<51:22:58,  1.87s/it]  1%|          | 763/99918 [30:51<47:25:15,  1.72s/it]  1%|          | 764/99918 [30:52<45:53:00,  1.67s/it]  1%|          | 765/99918 [30:54<44:55:36,  1.63s/it]  1%|          | 766/99918 [30:56<45:36:58,  1.66s/it]  1%|          | 767/99918 [30:58<55:44:05,  2.02s/it]  1%|          | 768/99918 [31:00<52:20:23,  1.90s/it]  1%|          | 769/99918 [31:02<50:36:06,  1.84s/it]  1%|          | 770/99918 [31:03<49:01:27,  1.78s/it]                                                        1%|          | 770/99918 [31:03<49:01:27,  1.78s/it]  1%|          | 771/99918 [31:05<47:32:03,  1.73s/it]  1%|          | 772/99918 [31:08<58:45:26,  2.13s/it]  1%|          | 773/99918 [31:10<54:05:43,  1.96s/it]  1%|          | 774/99918 [31:11<52:13:41,  1.90s/it]  1%|          | 775/99918 [31:37<251:52:43,  9.15s/it]  1%|          | 776/99918 [35:22<2029:57:11, 73.71s/it]  1%|          | 777/99918 [39:29<3465:33:13, 125.84s/it]  1%|          | 778/99918 [39:32<2445:37:25, 88.81s/it] 